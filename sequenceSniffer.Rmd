---
title: "repeated n-gram detection"
author: "Anne Rutten"
date: "January 31, 2020"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## aim:
flag data points that are part of a sequence that is present at least twice in a given data set.

### usage:

either just copy the `findDuplicates` function and run it inside your script, or use the interactive bit below to load your own .csv file


### `findDuplicates()`: identify duplicated sequences in a dataset

* works on data vectors (e.g., a dataframe column in 'long' format)
* function generates n-grams for given vector, iteratively increasing the sequence length from the specified `min_length` until no more duplicate n-grams are present in the data
* data points that are part of an n-gram that is present in the data more than once are marked with an identifier specific to the sequence

#### please note:

* the function does not yet check for overlapping sequences within a specific n-gram length, i.e. a sequence "A A B A A B A" will count and mark n-gram "A A B A" as duplicated
* longer sequences will overwrite shorter sequences that they overlap with, i.e., in the above example,3-gram "A B A" will be overwritten by 4-gram "A A B A".


#### dependencies & constants
```{r, message=FALSE }
library(tidyverse)
library(ngram)
library(shiny)
library(DT)
library(colorspace)

# for test run: Raphaels filename
fn <- "/home/anne/Pardosa_mesocosm_activity_P_R.csv"
```


#### ducttape-and-tiewraps wrapper around `ngram::ngram()`

* `somevector`: vector of values that needs to be tested for repeat sequences
* `min_length`: the minimum sequence length
* `ignoreAllEqual`: ignore n-grams that are repeats of one single value (trying to ignore defaults/censored data/etc)
* `sep`: in case this is a vector of strings, some separator that is not present in the data itself


```{r}

findDuplicates <- function(somevector, min_length, ignoreAllEqual=FALSE, sep=" ") {
  # paste all values into one string for n-gram calculation
  values_as_string <- paste(somevector, collapse= sep)

  # input data has to be coverted to character as well
  charactervector <- as.character(somevector)
  output <- data.frame(value=somevector, seqID = NA)
  done <- FALSE
  i <- min_length
  while (!done) {
    duplicates <- get.phrasetable(ngram(values_as_string, i, sep)) %>% 
                   filter(freq>1) %>%
                   select(ngrams) %>%
                   mutate(ngrams = strsplit(ngrams, " ")) # ngram() makes " " separated ngrams.
    
    if (ignoreAllEqual & nrow(duplicates)>0) duplicates <- filter(duplicates, rle(ngrams[[1]])$lengths[[1]]<i)
    if (nrow(duplicates)>0) {
      for(k in 1:nrow(duplicates)) {
        ng <- duplicates$ngrams[[k]]
        idx <- which(charactervector == ng[1])
        seqStart <- idx[sapply(idx, function(j) all(charactervector[j:(j+(length(ng)-1))] == ng))]
        output$seqID[rep(seqStart, each = i) + 0:(i-1)] <-paste0("n",i,"Seq",k)
      }
    }  else done=TRUE
    i<-i+1
 }
 output$seqID
}
 
```

## the interactive bit:

1. load a csv
2. identify the column range for which you want to flag duplicate n-grams (these will be transformed to `long` format)
3. check the output (use the filter function to find specific sequences)

the sequence id is generated as follows: <n>Seq<ngramID>, where `n` is the sequence length, and `ngramID` does not carry other information than that they're separate entities.

##### example usage in Raphaels data:

download from Raphaels github: https://github.com/rroyaute/Royaute-Pruitt-Ecology-2015-Data-and-Code/blob/master/Data%20files/Pardosa_mesocosm_activity_P_R.csv

```{r, echo=FALSE}
shinyApp(
  ui = fluidPage(
      h3("1: load datafile"),
    inputPanel(
        column(12,textAreaInput("filename", label ="filename: ",value=fn, width = 500
                ))),
     inputPanel(actionButton("readRaw", label = "get data")),
    
  
h3("2: select column range of data to detect sequences for"),
inputPanel(     numericInput("fromColumn", label = "focal column range start: ", value= 3),
                      numericInput("toColumn", label = "focal column range end: ", value=10),
                      numericInput("minGram", label = "minimum sequence length ", value=4),
                      checkboxInput("ignoreEqual", label = "ignore repeats of same value",  value = FALSE),
                      htmlOutput("groupingVarUI"),
                br(),
                      actionButton("run", label = "detect duplicates")
                
    ),
    h3("raw data:"),
    h5("rows that are not unique marked in blue"),
    DT::dataTableOutput("rawd"),
    h4("summary"),
    DT::dataTableOutput("dataSummary"),
    h3("with duplicated sequence IDs:"),
    h5(" coloured cells: sequence in column is not unique"),
    h5("grey cells: row is not unique"),
    downloadButton("downloadData","Download csv"),
    DT::dataTableOutput("duplicateNgramsWide"),
    h3("expected distribution of datapoints-in-duplicate-sequence:"),
    plotOutput("randoPlot")
    
  ),

server = function(input, output, session) {
  
  # load data 
  loadData <- eventReactive(input$readRaw,{
    dataLoaded <- TRUE
    d <- read.csv(input$filename)
     d$duplicatedRow <- (duplicated(d[,input$fromColumn:input$toColumn])|rev(duplicated(d[,input$fromColumn:input$toColumn] %>% map_df(rev))))
    d
    })
  
  output$rawd <- DT::renderDataTable({
    d <- loadData()
   
   datatable(d) %>%
   formatStyle(c(input$fromColumn:input$toColumn), "duplicatedRow", 
              backgroundColor = styleEqual(c(TRUE),"lightblue"))
   })
  
  # flag duplicate n-grams
  
  duplicateNgrams <- eventReactive(input$run, {
    d <-loadData()
    d$originalRowID <- row.names(d)
    longd <- gather(d, key, value, input$fromColumn:input$toColumn)
    longd$ngramID <- findDuplicates(longd$value, input$minGram, input$ignoreEqual)
    longd
    })
  
  duplicateNgramsWide <- reactive({
    duplicateNgrams <- duplicateNgrams()
    duplicateNgrams %>% pivot_wider(names_from =key, values_from=c(value, ngramID)) 
  })
  
  output$duplicateNgramsWide <- DT::renderDataTable({
    duplicateNgrams <- duplicateNgrams()
    duplicateNgramsWide <- duplicateNgramsWide()
    varnames <- names(duplicateNgramsWide)
    
    ids <- unique(duplicateNgrams$ngramID[!is.na(duplicateNgrams$ngramID)])
    cols <- rainbow_hcl(length(ids))

    varsToFormat <- varnames[grepl("value", varnames)]
    varsRef <- varnames[grepl("ngramID", varnames)]
    
    datatable(duplicateNgramsWide) %>%
      formatStyle(varsToFormat, "duplicatedRow", 
              backgroundColor = styleEqual(c(TRUE),"lightgrey")) %>%
      formatStyle(varsToFormat, varsRef, backgroundColor=styleEqual(ids,cols))
  })
  #summary
  dataSummary <-reactive({
     duplicateNgrams() %>% group_by(key) %>%     
                summarise(cardinality = n_distinct(value),
                          max_rle = with(rle(value) %>% set_names(c("lengths2", "values")), max(lengths2)),
                          max_rle_at_level = if (max_rle>1) with(rle(value) %>% set_names(c("lengths2", "values")), list(unique(values[lengths2==max(lengths2)]))) else list(NA),
                          n_duplicates = sum(!is.na(ngramID)),
                          n_total = n(),
                          fraction = round(n_duplicates/n_total,2)
                          )
    
  })
  output$dataSummary <- DT::renderDataTable({
   dataSummary()
  })
  
  # reactive input for grouping variables
  output$groupingVarUI <- renderUI({
      varnames <- names(loadData())
     selectInput("groupingVars", label = "reorder within (randomisation test)", 
                                  choices = varnames, selected =varnames[1],multiple = TRUE)
    
  })
  
  # randomisation test
  
  reorderAndReflag <- reactive({
    longd <- duplicateNgrams()

    groupedD <- group_by_at(longd, c(input$groupingVars,"key"))

    res <- list()

   for (i in 1:1000) {
    newd <- groupedD %>%
      mutate(newOrder = runif(n())) %>%
      arrange_at(c(input$groupingVars,"key","newOrder"))
  
      newd$newDupes <- findDuplicates(newd$value, input$minGram, input$ignoreEqual)
      res[[i]] <- group_by(newd, key) %>%
                  summarise(n_duplicates = sum(!is.na(newDupes)))
   }

   resdf <- bind_rows(res) %>%
            mutate(datasource = "simulated") %>%
            bind_rows(select(dataSummary(), key, n_duplicates) %>%
                      mutate(datasource = "actual data"))
 
  })
  
  output$randoPlot <- renderPlot({
    resdf <- reorderAndReflag()
    ggplot(as.data.frame(resdf), aes(n_duplicates, colour = datasource, fill=datasource)) +
  geom_bar() +
  theme_bw() +
  theme(legend.position="top") +
  facet_wrap(~key) +
  labs(title = "number of datapoints that are part of a duplicate sequence",
       subtitle =paste("data reordered within:", paste(input$groupingVars, collapse=", "), "\nn_runs=1000; minimum n-gram length =", input$minGram)) 
  })

  # download handler for flagged data
   output$downloadData <- downloadHandler(
    filename = function() {
      gsub(".csv",input$filename, paste0("_flagged_min_length_",input$minGram,".csv"))
    },
    content = function(file) {
      write.csv(duplicateNgramsWide(), file, row.names = FALSE)
    }
  )
},
options = list(height=5000))
  
```

